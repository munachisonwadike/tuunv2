{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddba42f9",
   "metadata": {},
   "source": [
    "***Dependencies***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63fb13d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install gpytorch\n",
    "# !pip install botorch\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1f62e6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Import Statements which we will need\"\"\"\n",
    "from botorch.acquisition import ExpectedImprovement, qExpectedImprovement\n",
    "from botorch.acquisition import IdentityMCObjective\n",
    "from botorch.acquisition.analytic import AnalyticAcquisitionFunction\n",
    "from botorch.acquisition.monte_carlo import MCAcquisitionFunction\n",
    "from botorch.acquisition.monte_carlo import qExpectedImprovement, qNoisyExpectedImprovement\n",
    "from botorch.acquisition.objective import (\n",
    "    IdentityMCObjective,\n",
    "    MCAcquisitionObjective,\n",
    "    PosteriorTransform,\n",
    ")\n",
    "from botorch.acquisition.objective import ConstrainedMCObjective\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch import fit_gpytorch_model\n",
    "\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models import FixedNoiseGP, ModelListGP\n",
    "\n",
    "from botorch.models.model import Model\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.optim.initializers import initialize_q_batch_nonneg\n",
    "from botorch.optim.optimize import optimize_acqf\n",
    "\n",
    "from botorch.sampling import SobolQMCNormalSampler\n",
    "from botorch.sampling import IIDNormalSampler\n",
    "from botorch.sampling.samplers import MCSampler, SobolQMCNormalSampler\n",
    "from botorch.test_functions import Beale, Branin, Hartmann \n",
    "# from botorch.test_functions.hartmann6 import neg_hartmann6\n",
    "from botorch.utils import standardize\n",
    "from botorch.utils import t_batch_mode_transform\n",
    "from botorch.utils.transforms import (\n",
    "    concatenate_pending_points,\n",
    "    match_batch_shape,\n",
    "    t_batch_mode_transform,\n",
    ")\n",
    "\n",
    "from gpytorch.kernels.matern_kernel import MaternKernel\n",
    "from gpytorch.kernels.linear_kernel import LinearKernel\n",
    "from gpytorch.kernels.piecewise_polynomial_kernel import PiecewisePolynomialKernel\n",
    "from gpytorch.kernels.polynomial_kernel import PolynomialKernel\n",
    "from gpytorch.kernels.rbf_kernel import RBFKernel\n",
    "from gpytorch.kernels.scale_kernel import ScaleKernel\n",
    "\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
    "from gpytorch.priors.torch_priors import GammaPrior\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from typing import Any, Dict, Optional, Tuple, Union\n",
    "from torch import Tensor\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import botorch\n",
    "import gpytorch\n",
    "import contextlib\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cfdf36",
   "metadata": {},
   "source": [
    "## **1. Setup** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d396aa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Parameters for how the code runs\n",
    "Note: true algorithm hyperparameters are defined in the main loop'''\n",
    "\n",
    "# Add 5, asterisks `#*****`, to the end of any line we modified or added from -> ||  https://botorch.org/v/0.1.4/tutorials/closed_loop_botorch_only '''\n",
    "\n",
    "warnings.filterwarnings('ignore', category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning) #*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70925ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'logistic function')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logistic = lambda z, const: 1./ (1 + np.exp(-const*z))       #logistic function\n",
    "z = np.linspace(-6,6,100)\n",
    "plt.subplots(1, 1, figsize=(4, 2))\n",
    "plt.plot(z, logistic(z, 100)*10 + 1, label=\"100\")\n",
    "plt.plot(z, logistic(z, 1)*10 + 1, label=\"1\")\n",
    "plt.plot(z, logistic(z, 5)*10 + 1, label=\"5\")\n",
    "plt.plot(z, logistic(z, 0.4)*10 + 1, label=\"0.4\")\n",
    "plt.xticks(np.arange(-6,6,1))\n",
    "plt.yticks(np.arange(1, 13, 2)) \n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.title('logistic function')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dc5fd3",
   "metadata": {},
   "source": [
    "## **2. Helper Functions** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40d672ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalize(val, norm_type=None, bounds=None): \n",
    "    if norm_type=='x': # we want in (0,1)\n",
    "        X = val + 0 # neat computational copy of X \n",
    "        for dim in range(len(bounds[0])):\n",
    "            X[:, dim] = (X[:, dim] - bounds[0][dim].item()) / (bounds[1][dim].item() - bounds[0][dim].item() ) # subtract the min bound and divide by the range to shift into (0,1)\n",
    "        return X\n",
    "\n",
    "    elif norm_type=='y' or norm_type=='c' or norm_type=='1/c':\n",
    "        Y = val + 0 # we want in (-1,1)\n",
    "        for dim in range(len(bounds[0])):\n",
    "            Y[:, dim] = (Y[:, dim] - bounds[0][dim].item()) / (bounds[1][dim].item() - bounds[0][dim].item() ) # subtract the min bound and divide by the range to shift into (0,1)\n",
    "        Y  = (Y * 2) - 1 \n",
    "        return Y \n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Sorry, ONLY x, y, or c values can be normalised\")\n",
    "\n",
    "\n",
    "def unnormalize(val, norm_type, orig_bounds=None):\n",
    "    if norm_type=='x': # from (0,1) to original bounds range\n",
    "        X = val + 0 # neat computational copy of val \n",
    "        for dim in range(len(orig_bounds[0])): # from (0,1) to orig range\n",
    "            X[:, dim] = X[:, dim] * (orig_bounds[1][dim].item() - orig_bounds[0][dim].item()) + (orig_bounds[0][dim].item()) \n",
    "        return X \n",
    "\n",
    "    elif norm_type=='y' or norm_type=='c' or norm_type=='1/c': # from (-1,1) to original bounds range; \n",
    "        # for cost values, we want to unnormalize in-between GP fitting and acq_fun optimisation\n",
    "        Y = val + 0\n",
    "        Y = (Y + 1) / 2 # normalise from (-1,1) into (0,1)\n",
    "        for dim in range(len(orig_bounds[0])): # from (-1,1) to orig range\n",
    "            Y[:, dim] = Y[:, dim] * (orig_bounds[1][dim].item() - orig_bounds[0][dim].item()) + (orig_bounds[0][dim].item()) \n",
    "        return Y \n",
    "    else:\n",
    "        raise Exception(\"Sorry, ONLY x, y, or c values can be UNnormalised\")\n",
    "\n",
    "def objective(X, cfg={}):\n",
    "    if cfg['fxn_name']=='test':\n",
    "        assert X.shape[1] == cfg['fxn_dim'] \n",
    "        return -(torch.linalg.norm(X, dim=-1))  \n",
    "    elif cfg['fxn_name']=='branin_4d':\n",
    "        # print(\"X==>\", X)\n",
    "        assert X.shape[1] == cfg['fxn_dim'] \n",
    "        return cfg['neg_branin2'](X[:,:2]) + cfg['neg_branin2'](X[:,2:])\n",
    "    elif cfg['fxn_name']=='branin_hartmann_8d':\n",
    "        assert X.shape[1] == cfg['fxn_dim'] \n",
    "        return cfg['neg_branin2'](X[:,:2]) + cfg['neg_hartmann6'](X[:,2:]) \n",
    "    elif cfg['fxn_name']=='beale_hartmann_7d':\n",
    "        assert X.shape[1] == cfg['fxn_dim']  \n",
    "        return cfg['neg_beale2'](X[:,:2]) + cfg['neg_hartmann3'](X[:,2:5]) + cfg['neg_beale2'](X[:,5:])\n",
    "    else:\n",
    "        print(\"ERROR! NEED TO ASSIGN ONE OF THESE FUNCTIONS!\") \n",
    "        \n",
    "        \n",
    "def get_random_observations(batch_size, bounds):\n",
    "    # Build random observation one dimension at a time\n",
    "    # This allows us to use different bounds for each hyperparameter\n",
    "    rand_x = torch.distributions.uniform.Uniform(bounds[0][0],bounds[1][0]).sample([batch_size,1])\n",
    "    for dim in range(1,len(bounds[0])):\n",
    "        temp = torch.distributions.uniform.Uniform(bounds[0][dim],bounds[1][dim]).sample([batch_size,1]) \n",
    "        rand_x = torch.cat((rand_x, temp), dim=1)\n",
    "    return rand_x \n",
    "\n",
    "def generate_initial_data(n, bounds, trial_seed=None, cfg={}): \n",
    "    torch.manual_seed(seed=trial_seed) \n",
    "    train_x = get_random_observations(batch_size=n, bounds=bounds)\n",
    "    train_y = objective(train_x,cfg=cfg).unsqueeze(-1)  # add output dimension\n",
    "    return train_x, train_y \n",
    "\n",
    "\n",
    "def sigmoid(z, const):\n",
    "    return 1./ (1 + torch.exp(-const*z))*10 + 1\n",
    "\n",
    "def generate_cost(train_x, cfg={}):  \n",
    "    if cfg['fxn_name']=='test':\n",
    "        assert train_x.shape[1] == cfg['fxn_dim'] \n",
    "        ret = sigmoid(train_x[:,0], 5) \n",
    "    elif cfg['fxn_name']=='branin_4d':\n",
    "        assert train_x.shape[1] == cfg['fxn_dim'] \n",
    "        # ret = CONSTANT + (train_x[:,0])**2 + (train_x[:,2])**2 +  torch.sqrt(torch.abs(train_x[:,3]))  # this one had numerical issuse due to sqrt-why?!!\n",
    "        # ret = CONSTANT + (train_x[:,0])**2 + (train_x[:,2])**2  \n",
    "        # print(\"TRAIN_X (Cost)\", train_x.shape, train_x[:,0].shape, train_x[:,2].shape, train_x[:,3].shape)\n",
    "        ret = cfg['CONSTANT'] + sigmoid(train_x[:,0],5) + (train_x[:,2]) + (train_x[:,3]) \n",
    "    elif cfg['fxn_name']=='branin_hartmann_8d':\n",
    "        assert train_x.shape[1] == cfg['fxn_dim'] \n",
    "        # ret = train_x[:,0] + (train_x[:,1])**2 + CONSTANT + torch.sqrt(torch.abs(train_x[:,4])) + train_x[:,5] + (train_x[:,6])**2 # this one had numerical issuse due to sqrt-why?!!\n",
    "        ret = train_x[:,0] + (train_x[:,1])**2 + cfg['CONSTANT'] + train_x[:,5] + (train_x[:,6])**2  \n",
    "    elif cfg['fxn_name']=='beale_hartmann_7d':\n",
    "        assert train_x.shape[1] == cfg['fxn_dim']  \n",
    "        ret = cfg['CONSTANT'] + (train_x[:,0]) + (train_x[:,1]) + (train_x[:,2]) + (train_x[:,3])**2 + (train_x[:,4])**2 + cfg['CONSTANT'] + (train_x[:,5]) + (train_x[:,6]) \n",
    "    else:\n",
    "        print(\"ERROR! NEED TO ASSIGN ONE OF THESE FUNCTIONS!\")\n",
    "        ret = None\n",
    "    return ret.unsqueeze(-1)  \n",
    "\n",
    "def initialize_model(train_x, train_y, state_dict=None, cost_kernel=None ):\n",
    "    init_x = train_x + 0\n",
    "    init_y = train_y + 0\n",
    "\n",
    "    model_obj = SingleTaskGP(init_x, init_y, covar_module=cost_kernel).to(init_x) # Just inheriting from PyTorch's module.to https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to\n",
    "    mll = ExactMarginalLogLikelihood(model_obj.likelihood, model_obj) \n",
    "    return mll, model_obj \n",
    " \n",
    "\n",
    "\n",
    "def optimize_acqf_and_get_observation(batch_size, acq_func, optim_bounds=None, r_seed=None):\n",
    "    \"\"\"Optimizes the acquisition function, and returns a new candidate and observation.\"\"\"\n",
    "    if acq_func==\"RAND\":\n",
    "        new_x = get_random_observations(batch_size, optim_bounds)\n",
    "        return new_x \n",
    "\n",
    "    candidates, _ = optimize_acqf( # https://github.com/pytorch/botorch/issues/371\n",
    "        acq_function=acq_func, \n",
    "        bounds=optim_bounds,\n",
    "        q=batch_size,\n",
    "        num_restarts=10,\n",
    "        raw_samples=500,  # used for intialization heuristic\n",
    "        # batch_initial_conditions=initials,\n",
    "        options={ \n",
    "            \"seed\": r_seed\n",
    "        }\n",
    "    )\n",
    "    # observe new values \n",
    "    new_x = candidates.detach()\n",
    "    return new_x "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eea83c6",
   "metadata": {},
   "source": [
    "## **3. Helper Functions**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "629629d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Code for EEIPU\n",
    "class EIPUVariants(AnalyticAcquisitionFunction): \n",
    "    r\"\"\"Modification of Standard Expected Improvement Class defined in BoTorch\n",
    "    See: https://botorch.org/api/_modules/botorch/acquisition/analytic.html#ExpectedImprovement\n",
    "    \"\"\" \n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: Model,\n",
    "        cost_model: Model,\n",
    "        best_f: Union[float, Tensor],\n",
    "        cost_sampler: Optional[MCSampler] = None,\n",
    "        acq_objective: Optional[MCAcquisitionObjective] = None,\n",
    "        posterior_transform: Optional[PosteriorTransform] = None,\n",
    "        maximize: bool = True,\n",
    "        acq_type: str = \"\", \n",
    "        cost_func = None,\n",
    "        unnormalise_func = None,\n",
    "        bounds: Tensor = None, # min, max\n",
    "        cfg: Dict = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        r\"\"\"q-Expected Improvement.\n",
    "\n",
    "        Args:\n",
    "            model: A fitted objective model.\n",
    "            cost_model: A fitted cost model.\n",
    "            best_f: The best objective value observed so far (assumed noiseless).  \n",
    "            cost_sampler: The sampler used to draw base samples.  \n",
    "            acq_objective: The MCAcquisitionObjective under which the samples are evaluated.\n",
    "                Defaults to `IdentityMCObjective()`.\n",
    "            posterior_transform: A PosteriorTransform (optional). \n",
    "            maximize: If True, consider the problem a maximization problem.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            model=model,  \n",
    "            posterior_transform=posterior_transform,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.maximize = maximize\n",
    "        if not torch.is_tensor(best_f):\n",
    "            best_f = torch.tensor(best_f)\n",
    "        self.register_buffer(\"best_f\", best_f)\n",
    "        self.cost_model = cost_model\n",
    "        self.cost_sampler = cost_sampler\n",
    "        self.acq_obj = acq_objective  \n",
    "        self.acq_type = acq_type\n",
    "        self.cost_func = cost_func\n",
    "        self.unnormalise_func = unnormalise_func\n",
    "        self.bounds = bounds\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def compute_expected_inverse_cost(self, X: Tensor) -> Tensor:\n",
    "        r\"\"\" Custom function. \n",
    "        \"\"\"\n",
    "        cost_posterior = self.cost_model.posterior(X)\n",
    "        cost_samples = self.cost_sampler(cost_posterior) \n",
    "        cost_samples = cost_samples.max(dim=2)[0]\n",
    "        # Note: Unnormalize Sampled Cost Values Here\n",
    "        if self.cfg['normalize_bit']['c']: # only unnormalize cost if we normalized it to fit the GP\n",
    "            cost_samples = self.unnormalise_func(cost_samples, norm_type='c', orig_bounds=self.bounds['c']) \n",
    "        cost_obj = self.acq_obj(cost_samples)\n",
    "        inv_cost =  1/cost_obj\n",
    "        inv_cost =  inv_cost.mean(dim=0)\n",
    "        return inv_cost\n",
    "\n",
    "\n",
    "    def direct_expected_inverse_cost(self, X: Tensor) -> Tensor:\n",
    "        r\"\"\" TO-DO.\n",
    "        \"\"\"\n",
    "        cost_posterior = self.cost_model.posterior(X) \n",
    "        mean = cost_posterior.mean\n",
    "        if self.cfg['normalize_bit']['1/c']: # only unnormalize cost if we normalized it to fit the GP\n",
    "            mean = self.unnormalise_func(mean, norm_type='1/c', orig_bounds=self.bounds['1/c']) \n",
    "        return mean.squeeze()\n",
    "\n",
    "    def compute_expected_cost(self, X: Tensor) -> Tensor:\n",
    "        r\"\"\" Custom function.\n",
    "        Used for debugging the return value of expected inverse cont function above.\n",
    "        \"\"\"\n",
    "        cost_posterior = self.cost_model.posterior(X)\n",
    "        cost_samples = self.cost_sampler(cost_posterior) \n",
    "        cost_samples = cost_samples.max(dim=2)[0]\n",
    "        # Note: Unnormalize Sampled Cost Values Here\n",
    "        if self.cfg['normalize_bit']['c']: # only unnormalize cost if we normalized it to fit the GP\n",
    "            cost_samples = self.unnormalise_func(cost_samples, norm_type='c', orig_bounds=self.bounds['c']) \n",
    "        cost_obj = self.acq_obj(cost_samples) \n",
    "        return cost_obj.mean(dim=0)\n",
    "\n",
    "    @t_batch_mode_transform(expected_q=1, assert_output_shape=False)\n",
    "    def forward(self, X: Tensor) -> Tensor:\n",
    "        r\"\"\"Evaluate qExpectedImprovement on the candidate set `X`.\n",
    "        \"\"\" \n",
    "        self.best_f = self.best_f.to(X)\n",
    "        posterior = self.model.posterior(\n",
    "          X=X, posterior_transform=self.posterior_transform\n",
    "        )\n",
    "        mean = posterior.mean\n",
    "        view_shape = mean.shape[:-2] if mean.shape[-2] == 1 else mean.shape[:-1]\n",
    "        mean = mean.view(view_shape)\n",
    "        sigma = posterior.variance.clamp_min(1e-9).sqrt().view(view_shape)\n",
    "        u = (mean - self.best_f.expand_as(mean)) / sigma\n",
    "        if not self.maximize:\n",
    "            u = -u\n",
    "        normal = Normal(torch.zeros_like(u), torch.ones_like(u))\n",
    "        ucdf = normal.cdf(u)\n",
    "        updf = torch.exp(normal.log_prob(u))\n",
    "        ei = sigma * (updf + u * ucdf)\n",
    "        if self.acq_type == \"EIPU\":\n",
    "            if self.cfg['normalize_bit']['x']: # if X was normalized pre-GP-fit, unnormalize for true cost calculation\n",
    "                X_new = self.unnormalise_func(X.squeeze(1) + 0, norm_type='x', orig_bounds=self.bounds['x'])   \n",
    "                return ei / self.cost_func(X_new, cfg=self.cfg).squeeze()  \n",
    "            return ei / self.cost_func(X.squeeze(1), cfg=self.cfg).squeeze() # otherwise just calculate cost straightup\n",
    "     \n",
    "        elif self.acq_type == \"EEIPU\":\n",
    "            inv_cost =  self.compute_expected_inverse_cost(X)\n",
    "            return ei * inv_cost\n",
    "      \n",
    "        elif self.acq_type == \"EEIPU-INV\":\n",
    "            inv_cost = self.direct_expected_inverse_cost(X)\n",
    "            return ei * inv_cost\n",
    "        else:\n",
    "            raise Exception(\"ERROR: Only EIPU, EEIPU, EEIPU-INV are supported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e298681f",
   "metadata": {},
   "source": [
    "## **4. Single BO Step**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51b9daf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def single_bo_iteration(dataset={}, bounds={}, acq_type='', cfg={}):\n",
    "    cost_model, cost_sampler={}, {}\n",
    "    # (A) Normalize the dataset Points (only normalize cost if we are using acqfunc that needs cost model)\n",
    "    # NOTE: single-line if statements used here\n",
    "    train_x = normalize(dataset['x'], norm_type='x', bounds=bounds['x']) if cfg['normalize_bit']['x'] else dataset['x']\n",
    "    train_obj = normalize(dataset['y'], norm_type='y', bounds=bounds['y'])  if cfg['normalize_bit']['y'] else dataset['y']\n",
    "    if acq_type=='EEIPU': # cover potential cost model value normalisation\n",
    "        train_cost = normalize(dataset['c'], norm_type='c', bounds=bounds['c']) if cfg['normalize_bit']['c'] else dataset['c']\n",
    "    if acq_type=='EEIPU-INV': # cover potential inverse cost model value normalisation\n",
    "        train_cost = normalize(dataset['1/c'], norm_type='1/c', bounds=bounds['1/c']) if cfg['normalize_bit']['1/c'] else dataset['1/c']\n",
    "\n",
    "    # (B) Initialise/Re-initialize & Fit/Refit the GP models (only initialise cost model if we'll need it)\n",
    "    mll, model= initialize_model(train_x, train_obj) \n",
    "    fit_gpytorch_model(mll);\n",
    "    if acq_type in ['EEIPU', 'EEIPU-INV']: \n",
    "        cost_mll, cost_model= initialize_model(train_x, train_cost, cost_kernel=cfg['cost_kernel'])  \n",
    "        fit_gpytorch_model(cost_mll)\n",
    "\n",
    "    # (C) Redefine acquisition function & optimise  \n",
    "    if (acq_type=='RAND'):\n",
    "        acqf = 'RAND'\n",
    "    elif (acq_type=='EI'):\n",
    "        acqf = ExpectedImprovement(model=model, best_f=train_obj.max())\n",
    "    elif (acq_type=='EIPU') or (acq_type=='EEIPU') or (acq_type=='EEIPU-INV'):\n",
    "        cost_sampler = SobolQMCNormalSampler(num_samples=cfg['cost_samples'], resample=True, seed=cfg['rand_seed'])\n",
    "        acqf = EIPUVariants(acq_type=acq_type, model=model, cost_model=cost_model, \n",
    "                 best_f=train_obj.max(), \n",
    "                 cost_sampler=cost_sampler, acq_objective=IdentityMCObjective(),   \n",
    "                 cost_func=generate_cost, unnormalise_func=unnormalize, bounds=bounds,\n",
    "                 cfg=cfg)\n",
    " \n",
    "    if acq_type == 'RAND':\n",
    "        new_x = optimize_acqf_and_get_observation(batch_size=cfg['batch_size'], acq_func=acq_type, \n",
    "                                              optim_bounds=bounds['x'], r_seed=cfg['rand_seed']) # includes random search option, for code neatness \n",
    "    else: # careful with bounds for non random acqfunctions - single line if statement used here\n",
    "        normalised_bounds = normalize(bounds['x'], norm_type='x', bounds=bounds['x']) if cfg['normalize_bit']['x'] else bounds['x']  # Need too normalize the bounds used in the acqfunction too!\n",
    "        new_x = optimize_acqf_and_get_observation(batch_size=cfg['batch_size'], acq_func=acqf,  # includes random search option, for code neatness \n",
    "                                            optim_bounds=normalised_bounds, r_seed=cfg['rand_seed'])\n",
    "    # (D) Unnormalize the X value and return (also mc value since we can't compute outside this func)\n",
    "    cost_model_mean = torch.tensor([0]); \n",
    "    if acq_type == 'EEIPU': cost_model_mean = acqf.compute_expected_cost(new_x)\n",
    "    if acq_type == 'EEIPU-INV': cost_model_mean = acqf.direct_expected_inverse_cost(new_x)\n",
    "    if cfg['normalize_bit']['x'] and acq_type != 'RAND' : new_x = unnormalize(new_x, norm_type='x', orig_bounds=bounds['x'])# cat with unnormalised x here\n",
    "    return new_x, cost_model_mean.item()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd311f8",
   "metadata": {},
   "source": [
    "## **5.0 BO Inner Loops (Multiple Steps)**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17a0b9eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bo_inner_loops(trial_number=None, x_bounds=None, acq_type='', cfg={}):\n",
    "    print(f\"TRIAL #{trial_number} Acq-Type: [{acq_type}]\")\n",
    "    log_vals  = {'f(x^)': [],'x': [], 'f(x)': [], 'c(x)': [], 'mc(x)': [], '1/c(x)': [], 'c(c)':[]} # f(x^) = best obj val so far; c(c) is cumulative cost  \n",
    "\n",
    "    dataset, bounds = {},{}\n",
    "    # (A) Initialize dataset for all the different acq function types  \n",
    "    dataset['x'], dataset['y'] = generate_initial_data(n=cfg['num_initial_data'], bounds=x_bounds, trial_seed=trial_number, cfg=cfg); \n",
    "    dataset['c'] = generate_cost(dataset['x'], cfg=cfg) \n",
    "    dataset['1/c'] = 1/dataset['c'] \n",
    "\n",
    "    log_vals['c(c)'].append(dataset['c'].sum().item())\n",
    "    log_vals['f(x^)'].append(objective(dataset['x'], cfg=cfg).max().item())\n",
    "\n",
    "    # (B) run N_ITERS rounds of BayesOpt after the initial random batch\n",
    "    for iteration in range(cfg['n_iters']):    \n",
    "        bounds['x'] = x_bounds # bounds written as min,max not max,min\n",
    "        bounds['y'] = torch.tensor([[dataset['y'].min()], [dataset['y'].max()]], device=cfg['device'], dtype=cfg['dtype'])\n",
    "        bounds['c'] = torch.tensor([[dataset['c'].min()], [dataset['c'].max()]], device=cfg['device'], dtype=cfg['dtype'])\n",
    "        bounds['1/c'] = torch.tensor([[dataset['1/c'].min()], [dataset['1/c'].max()]], device=cfg['device'], dtype=cfg['dtype'])\n",
    "\n",
    "        # (B.0) At each single iteration, we pass the dataset and take the next suggested point\n",
    "        new_x, mc_x = single_bo_iteration(dataset=dataset, bounds=bounds, acq_type=acq_type, cfg=cfg )\n",
    "\n",
    "        new_obj = objective(new_x, cfg=cfg).unsqueeze(-1)  # add output dimension \n",
    "        new_cost = generate_cost(new_x, cfg=cfg)  \n",
    "\n",
    "        dataset['x'] = torch.cat([dataset['x'], new_x]) \n",
    "        dataset['y'] = torch.cat([dataset['y'], new_obj])  \n",
    "        dataset['c'] = torch.cat([dataset['c'], new_cost])       \n",
    "        dataset['1/c'] = torch.cat([dataset['1/c'], 1/new_cost])       \n",
    "\n",
    "        log_vals['f(x^)'].append(objective(dataset['x'], cfg=cfg).max().item())\n",
    "        log_vals['x'] = np.array(new_x.cpu())\n",
    "        log_vals['f(x)'].append(new_obj.item())\n",
    "        log_vals['c(x)'].append(new_cost.item())\n",
    "        log_vals['c(c)'].append(log_vals['c(c)'][-1]+ new_cost.item())\n",
    "        log_vals['mc(x)'] = mc_x\n",
    "        log_vals['1/c(x)'].append((1/new_cost).item())\n",
    "\n",
    "        if cfg['verbose']:\n",
    "            print(f\"Iteration-{iteration} [{acq_type}] Trial No. #{trial_number}\"\n",
    "              f\"\\nf(x^)={log_vals['f(x^)'][-1]:>4.3f}\"\n",
    "              f\"\\tf(x)={log_vals['f(x)'][-1]:>4.3f}\"\n",
    "              f\"\\tc(x) = {log_vals['c(x)'][-1]:>4.3f}\"\n",
    "              f\"\\tmc(x) = {log_vals['mc(x)']:>4.3f}\" \n",
    "              f\"\\t1/c(x) = {log_vals['1/c(x)'][-1]:>4.3f}\" \n",
    "              f\"\\tc(c) = {log_vals['c(c)'][-1]:>4.3f}\")\n",
    "\n",
    "    return log_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b85bb7a",
   "metadata": {},
   "source": [
    "## **5.1. BO Outer Loops (Multiple Trials)**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d3fc8a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bo_trials(cfg={}, acq_type=''):\n",
    "\n",
    "    torch.manual_seed(seed=cfg['rand_seed'])\n",
    "    np.random.seed(cfg['rand_seed'])\n",
    "    random.seed(cfg['rand_seed'])\n",
    "    botorch.utils.sampling.manual_seed(seed=cfg['rand_seed'])\n",
    "    # https://github.com/pytorch/botorch/issues/371\n",
    "\n",
    "\n",
    "    x_bounds = torch.tensor([[cfg['x_bounds'][0]] * cfg['fxn_dim'], [cfg['x_bounds'][1]] * cfg['fxn_dim']], device=cfg['device'], dtype=cfg['dtype'])\n",
    "    log_vals_all  = {'f(x^)': [],'x': [], 'f(x)': [], 'c(x)': [], 'mc(x)': [], 'c(c)':[]}\n",
    "    print(\"\\n\\nnormalize_bit\", cfg['normalize_bit'])\n",
    "    # average over multiple trials\n",
    "    for trial in range(1, cfg['n_trials'] + 1):\n",
    "\n",
    "        log_vals = bo_inner_loops(trial_number=trial, x_bounds=x_bounds, acq_type=acq_type, cfg=main_cfg)\n",
    "\n",
    "        for key in log_vals_all.keys():\n",
    "            print(\"KEY->\", key)\n",
    "            log_vals_all[key].append(log_vals[key])\n",
    "            if trial==cfg['n_trials']: log_vals_all[key] = np.array(log_vals_all[key])# save as np array on the last trial    \n",
    "    return log_vals_all\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15a138a",
   "metadata": {},
   "source": [
    "## **5.2. BO Methods (Multiple Acquisitions)**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4b631bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n",
      "0\n",
      "<torch.cuda.device object at 0x7fa00cac2910>\n",
      "NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af43f73e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "normalize_bit {'x': True, 'y': True, 'c': True, '1/c': True}\n",
      "TRIAL #1 Acq-Type: [RAND]\n",
      "Iteration-0 [RAND] Trial No. #1\n",
      "f(x^)=-19.246\tf(x)=-247.106\tc(x) = 7.384\tmc(x) = 0.000\t1/c(x) = 0.135\tc(c) = 78.636\n",
      "Iteration-1 [RAND] Trial No. #1\n",
      "f(x^)=-19.246\tf(x)=-33.581\tc(x) = 13.877\tmc(x) = 0.000\t1/c(x) = 0.072\tc(c) = 92.512\n",
      "Iteration-2 [RAND] Trial No. #1\n",
      "f(x^)=-19.246\tf(x)=-88.179\tc(x) = 10.889\tmc(x) = 0.000\t1/c(x) = 0.092\tc(c) = 103.401\n",
      "Iteration-3 [RAND] Trial No. #1\n",
      "f(x^)=-19.246\tf(x)=-73.974\tc(x) = 10.966\tmc(x) = 0.000\t1/c(x) = 0.091\tc(c) = 114.367\n",
      "Iteration-4 [RAND] Trial No. #1\n",
      "f(x^)=-19.246\tf(x)=-58.352\tc(x) = 10.694\tmc(x) = 0.000\t1/c(x) = 0.094\tc(c) = 125.061\n",
      "Iteration-5 [RAND] Trial No. #1\n",
      "f(x^)=-19.246\tf(x)=-122.731\tc(x) = 8.220\tmc(x) = 0.000\t1/c(x) = 0.122\tc(c) = 133.282\n",
      "Iteration-6 [RAND] Trial No. #1\n",
      "f(x^)=-19.246\tf(x)=-130.491\tc(x) = 2.670\tmc(x) = 0.000\t1/c(x) = 0.374\tc(c) = 135.952\n",
      "Iteration-7 [RAND] Trial No. #1\n",
      "f(x^)=-19.246\tf(x)=-45.071\tc(x) = 9.963\tmc(x) = 0.000\t1/c(x) = 0.100\tc(c) = 145.915\n",
      "Iteration-8 [RAND] Trial No. #1\n",
      "f(x^)=-19.246\tf(x)=-68.151\tc(x) = 10.915\tmc(x) = 0.000\t1/c(x) = 0.092\tc(c) = 156.830\n",
      "Iteration-9 [RAND] Trial No. #1\n",
      "f(x^)=-19.246\tf(x)=-112.336\tc(x) = 12.313\tmc(x) = 0.000\t1/c(x) = 0.081\tc(c) = 169.143\n",
      "Iteration-10 [RAND] Trial No. #1\n",
      "f(x^)=-19.246\tf(x)=-31.702\tc(x) = 17.001\tmc(x) = 0.000\t1/c(x) = 0.059\tc(c) = 186.145\n",
      "Iteration-11 [RAND] Trial No. #1\n",
      "f(x^)=-19.246\tf(x)=-227.538\tc(x) = 2.791\tmc(x) = 0.000\t1/c(x) = 0.358\tc(c) = 188.936\n",
      "Iteration-12 [RAND] Trial No. #1\n",
      "f(x^)=-19.246\tf(x)=-90.918\tc(x) = 11.122\tmc(x) = 0.000\t1/c(x) = 0.090\tc(c) = 200.058\n",
      "Iteration-13 [RAND] Trial No. #1\n",
      "f(x^)=-19.246\tf(x)=-134.012\tc(x) = -0.132\tmc(x) = 0.000\t1/c(x) = -7.589\tc(c) = 199.926\n",
      "Iteration-14 [RAND] Trial No. #1\n",
      "f(x^)=-19.246\tf(x)=-575.131\tc(x) = -4.901\tmc(x) = 0.000\t1/c(x) = -0.204\tc(c) = 195.024\n",
      "Iteration-15 [RAND] Trial No. #1\n",
      "f(x^)=-19.246\tf(x)=-102.804\tc(x) = 0.997\tmc(x) = 0.000\t1/c(x) = 1.003\tc(c) = 196.021\n",
      "Iteration-16 [RAND] Trial No. #1\n",
      "f(x^)=-19.246\tf(x)=-529.242\tc(x) = -1.754\tmc(x) = 0.000\t1/c(x) = -0.570\tc(c) = 194.268\n",
      "Iteration-17 [RAND] Trial No. #1\n",
      "f(x^)=-19.246\tf(x)=-221.360\tc(x) = 5.346\tmc(x) = 0.000\t1/c(x) = 0.187\tc(c) = 199.614\n",
      "Iteration-18 [RAND] Trial No. #1\n",
      "f(x^)=-19.246\tf(x)=-66.779\tc(x) = 11.868\tmc(x) = 0.000\t1/c(x) = 0.084\tc(c) = 211.482\n",
      "Iteration-19 [RAND] Trial No. #1\n",
      "f(x^)=-19.246\tf(x)=-100.675\tc(x) = 10.212\tmc(x) = 0.000\t1/c(x) = 0.098\tc(c) = 221.694\n"
     ]
    }
   ],
   "source": [
    "# Batch size in original tutorial meant q-batch size https://botorch.org/v/0.1.4/tutorials/closed_loop_botorch_only ||  # lower bound and upper bound could be -float('inf') ~ float('inf')\n",
    "main_cfg = {\n",
    "'batch_size':1, 'x_bounds': [-5,5],  \n",
    "'CONSTANT':.5,\n",
    "'cost_samples': 50, # mc cost samples\n",
    "'cost_kernel': None, \n",
    "'device': torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), 'dtype': torch.double,\n",
    "'fxn_name':'branin_4d', # {'test':3, 'branin_4d':4, 'beale_hartmann_7d':7,  'branin_hartmann_8d':8},   \n",
    "'fxn_dim':4, # {'test':3, 'branin_4d':4, 'beale_hartmann_7d':7,  'branin_hartmann_8d':8},   \n",
    "'neg_hartmann6':Hartmann(negate=True),\n",
    "'neg_beale2':Beale(negate=True),\n",
    "'neg_branin2':Branin(negate=True),\n",
    "'neg_hartmann3':Hartmann(dim=3, negate=True), \n",
    "'n_trials':10,\n",
    "'n_iters':30,\n",
    "'num_initial_data':10,\n",
    "'verbose':True,\n",
    "'normalize_bit':{'x':True, 'y':True, 'c':True, '1/c':True}, \n",
    "'rand_seed': 0,\n",
    "}\n",
    " \n",
    "# (C) Do the above for each of the different acquisition function types\n",
    "plot_vals = {}\n",
    "\n",
    "plot_vals['RAND'] = bo_trials(cfg=main_cfg, acq_type='RAND') \n",
    "# plot_vals['RAND2'] = bo_trials(cfg=main_cfg, acq_type='RAND')  \n",
    "plot_vals['EI'] = bo_trials(cfg=main_cfg, acq_type='EI') \n",
    "plot_vals['EIPU'] = bo_trials(cfg=main_cfg, acq_type='EIPU') \n",
    "plot_vals['EEIPU'] = bo_trials(cfg=main_cfg, acq_type='EEIPU') \n",
    "plot_vals['EEIPU-INV'] = bo_trials(cfg=main_cfg, acq_type='EEIPU-INV') \n",
    "# dfsdsdfsd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd80581b",
   "metadata": {},
   "source": [
    "## **6.0. Plotting and Value Analyses**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d94c65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from botorch.test_functions.hartmann6 import GLOBAL_MAXIMUM\n",
    "\n",
    "%matplotlib inline\n",
    "def ci(y):\n",
    "    # return 1.96 * y.std(axis=0) / np.sqrt(N_TRIALS)\n",
    "    return y.std(axis=0) \n",
    "\n",
    "# GLOBAL_MAXIMUM = 3.32237\n",
    "GLOBAL_MAXIMUM = 0\n",
    "iters = np.arange(main_cfg['n_iters']+1) * main_cfg['batch_size']\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(22, 4))\n",
    "\n",
    "ax1.plot([0, main_cfg['n_iters'] * main_cfg['batch_size'] ], [GLOBAL_MAXIMUM] * 2, 'k', label=\"true best objective\", linewidth=2)\n",
    "\n",
    "types = ['RAND', 'EI', 'EIPU','EEIPU','EEIPU-INV',] \n",
    " \n",
    "for type_ in types:\n",
    "    ax1.errorbar(iters, plot_vals[type_]['f(x^)'].mean(axis=0), \n",
    "               yerr=ci(plot_vals[type_]['f(x^)']), label=type_, linewidth=1) \n",
    "    # Can exclude cumumulative cost of random warmup points using `[:,1:]`, of course\n",
    "    ax2.errorbar(plot_vals[type_]['c(c)'].mean(axis=0), plot_vals[type_]['f(x^)'].mean(axis=0), \n",
    "               yerr=ci(plot_vals[type_]['f(x^)']), label=type_, linewidth=1) \n",
    "    ax3.plot(plot_vals[type_]['c(x)'].mean(axis=0), plot_vals[type_]['f(x^)'][:,1:].mean(axis=0), \n",
    "              label=type_, linewidth=1)\n",
    "    ax4.errorbar(plot_vals[type_]['f(x^)'].mean(axis=0), plot_vals[type_]['c(c)'].mean(axis=0), \n",
    "               yerr=ci(plot_vals[type_]['c(c)']), label=type_, linewidth=1.5)\n",
    "    ### Use this to replace error bars with fill\n",
    "    # ax3.fill_between(cum_cost_ei.mean(axis=0), y1=y_ei.mean(axis=0)-y_ei.std(axis=0), y2=y_ei.mean(axis=0)+y_ei.std(axis=0), label=\"EI\", alpha=.5, linewidth=0)\n",
    "    # ax1.set_xlim(right=20); # ax1.set_ylim(bottom=0.5); \n",
    "\n",
    "ax1.set(xlabel='number of observations (beyond initial points)', ylabel='Best Objective Value')\n",
    "ax1.legend(loc=\"lower right\")\n",
    "ax2.set(xlabel='Cumulative Cost of observations', ylabel='Best Objective Value')\n",
    "ax2.legend(loc=\"lower right\")  \n",
    "ax3.set(xlabel='Cost of observations', ylabel='Best Objective Value')\n",
    "ax3.legend(loc=\"lower right\")\n",
    "ax4.set(xlabel='Best Objective Value', ylabel='Cumulative Cost of observations')\n",
    "ax4.legend(loc=\"lower right\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
