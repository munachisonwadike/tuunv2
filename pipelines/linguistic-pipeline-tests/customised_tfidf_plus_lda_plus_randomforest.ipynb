{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1fc4ab0",
   "metadata": {},
   "source": [
    "Citation: https://www.kaggle.com/code/baghern/a-deep-dive-into-sklearn-pipelines \\\n",
    "But with a lot of modifications! e.g throwing out the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c275d4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text author\n",
       "id                                                               \n",
       "id26305  This process, however, afforded me no means of...    EAP\n",
       "id17569  It never once occurred to me that the fumbling...    HPL\n",
       "id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "df = pd.read_csv('./data/train.csv')\n",
    "\n",
    "df.dropna(axis=0)\n",
    "df.set_index('id', inplace = True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56b5a2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>processed</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>words_not_stopword</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>commas</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>this process however afforded me no means of a...</td>\n",
       "      <td>224</td>\n",
       "      <td>41</td>\n",
       "      <td>21</td>\n",
       "      <td>6.380952</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>it never once occurred to me that the fumbling...</td>\n",
       "      <td>70</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>in his left hand was a gold snuff box from whi...</td>\n",
       "      <td>195</td>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>5.947368</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>how lovely is spring as we looked from windsor...</td>\n",
       "      <td>202</td>\n",
       "      <td>34</td>\n",
       "      <td>21</td>\n",
       "      <td>6.476190</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>finding nothing else not even gold the superin...</td>\n",
       "      <td>170</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>7.187500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text author  \\\n",
       "id                                                                  \n",
       "id26305  This process, however, afforded me no means of...    EAP   \n",
       "id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "                                                 processed  length  words  \\\n",
       "id                                                                          \n",
       "id26305  this process however afforded me no means of a...     224     41   \n",
       "id17569  it never once occurred to me that the fumbling...      70     14   \n",
       "id11008  in his left hand was a gold snuff box from whi...     195     36   \n",
       "id27763  how lovely is spring as we looked from windsor...     202     34   \n",
       "id12958  finding nothing else not even gold the superin...     170     27   \n",
       "\n",
       "         words_not_stopword  avg_word_length  commas  \n",
       "id                                                    \n",
       "id26305                  21         6.380952       4  \n",
       "id17569                   6         6.166667       0  \n",
       "id11008                  19         5.947368       4  \n",
       "id27763                  21         6.476190       3  \n",
       "id12958                  16         7.187500       2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "#creating a function to encapsulate preprocessing, to mkae it easy to replicate on  submission data\n",
    "def processing(df):\n",
    "    #lowering and removing punctuation\n",
    "    df['processed'] = df['text'].apply(lambda x: re.sub(r'[^\\w\\s]','', x.lower()))\n",
    "    \n",
    "    #numerical feature engineering\n",
    "    #total length of sentence\n",
    "    df['length'] = df['processed'].apply(lambda x: len(x))\n",
    "    #get number of words\n",
    "    df['words'] = df['processed'].apply(lambda x: len(x.split(' ')))\n",
    "    df['words_not_stopword'] = df['processed'].apply(lambda x: len([t for t in x.split(' ') if t not in stopWords]))\n",
    "    #get the average word length\n",
    "    df['avg_word_length'] = df['processed'].apply(lambda x: np.mean([len(t) for t in x.split(' ') if t not in stopWords]) if len([len(t) for t in x.split(' ') if t not in stopWords]) > 0 else 0)\n",
    "    #get the average word length\n",
    "    df['commas'] = df['text'].apply(lambda x: x.count(','))\n",
    "\n",
    "    return(df)\n",
    "\n",
    "df = processing(df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3802aa95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>words_not_stopword</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>commas</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id19417</th>\n",
       "      <td>this panorama is indeed glorious and i should ...</td>\n",
       "      <td>91</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09522</th>\n",
       "      <td>there was a simple natural earnestness about h...</td>\n",
       "      <td>240</td>\n",
       "      <td>44</td>\n",
       "      <td>18</td>\n",
       "      <td>6.277778</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id22732</th>\n",
       "      <td>who are you pray that i duc de lomelette princ...</td>\n",
       "      <td>387</td>\n",
       "      <td>74</td>\n",
       "      <td>38</td>\n",
       "      <td>5.552632</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id10351</th>\n",
       "      <td>he had gone in the carriage to the nearest tow...</td>\n",
       "      <td>118</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>5.363636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24580</th>\n",
       "      <td>there is no method in their proceedings beyond...</td>\n",
       "      <td>71</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 processed  length  words  \\\n",
       "id                                                                          \n",
       "id19417  this panorama is indeed glorious and i should ...      91     18   \n",
       "id09522  there was a simple natural earnestness about h...     240     44   \n",
       "id22732  who are you pray that i duc de lomelette princ...     387     74   \n",
       "id10351  he had gone in the carriage to the nearest tow...     118     24   \n",
       "id24580  there is no method in their proceedings beyond...      71     13   \n",
       "\n",
       "         words_not_stopword  avg_word_length  commas  \n",
       "id                                                    \n",
       "id19417                   6         6.666667       1  \n",
       "id09522                  18         6.277778       4  \n",
       "id22732                  38         5.552632       9  \n",
       "id10351                  11         5.363636       0  \n",
       "id24580                   5         7.000000       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features= [c for c in df.columns.values if c  not in ['id','text','author']]\n",
    "numeric_features= [c for c in df.columns.values if c  not in ['id','text','author','processed']]\n",
    "target = 'author'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.33, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a13dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa42a2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**1 (13117, 21516) (13117, 6)\n",
      "**2 (13117, 8) (13117, 6)\n",
      "Total Time: 32.98590350151062\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "text = Pipeline([\n",
    "                ('selector', TextSelector(key='processed')),\n",
    "                ('tfidf', TfidfVectorizer( stop_words='english'))\n",
    "                \n",
    "            ])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('text',text),  \n",
    "])\n",
    "\n",
    "X_transformed = pipeline.fit_transform(X_train)\n",
    "print(\"**1\", X_transformed.shape, X_train.shape)\n",
    " \n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('text',text),\n",
    "    ('lda', LatentDirichletAllocation(n_components=8, learning_method='online', \n",
    "                                          random_state=0, verbose=0, n_jobs = -1) )\n",
    "])\n",
    "\n",
    "X_transformed = pipeline.fit_transform(X_train)\n",
    "print(\"**2\", X_transformed.shape, X_train.shape)\n",
    " \n",
    "pipeline = Pipeline([\n",
    "    ('text',text),\n",
    "    ('lda', LatentDirichletAllocation(n_components=8, learning_method='online', \n",
    "                                          random_state=0, verbose=0, n_jobs = -1) ),\n",
    "    ('classifier', RandomForestClassifier(random_state = 42)),\n",
    "])\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "preds = pipeline.predict(X_test)\n",
    "np.mean(preds == y_test)\n",
    "print(\"Total Time:\", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fc3dd6",
   "metadata": {},
   "source": [
    "### GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f90c1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'text', 'lda', 'classifier', 'text__memory', 'text__steps', 'text__verbose', 'text__selector', 'text__tfidf', 'text__selector__key', 'text__tfidf__analyzer', 'text__tfidf__binary', 'text__tfidf__decode_error', 'text__tfidf__dtype', 'text__tfidf__encoding', 'text__tfidf__input', 'text__tfidf__lowercase', 'text__tfidf__max_df', 'text__tfidf__max_features', 'text__tfidf__min_df', 'text__tfidf__ngram_range', 'text__tfidf__norm', 'text__tfidf__preprocessor', 'text__tfidf__smooth_idf', 'text__tfidf__stop_words', 'text__tfidf__strip_accents', 'text__tfidf__sublinear_tf', 'text__tfidf__token_pattern', 'text__tfidf__tokenizer', 'text__tfidf__use_idf', 'text__tfidf__vocabulary', 'lda__batch_size', 'lda__doc_topic_prior', 'lda__evaluate_every', 'lda__learning_decay', 'lda__learning_method', 'lda__learning_offset', 'lda__max_doc_update_iter', 'lda__max_iter', 'lda__mean_change_tol', 'lda__n_components', 'lda__n_jobs', 'lda__perp_tol', 'lda__random_state', 'lda__topic_word_prior', 'lda__total_samples', 'lda__verbose', 'classifier__bootstrap', 'classifier__ccp_alpha', 'classifier__class_weight', 'classifier__criterion', 'classifier__max_depth', 'classifier__max_features', 'classifier__max_leaf_nodes', 'classifier__max_samples', 'classifier__min_impurity_decrease', 'classifier__min_samples_leaf', 'classifier__min_samples_split', 'classifier__min_weight_fraction_leaf', 'classifier__n_estimators', 'classifier__n_jobs', 'classifier__oob_score', 'classifier__random_state', 'classifier__verbose', 'classifier__warm_start'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bda14215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;text&#x27;,\n",
       "                                        Pipeline(steps=[(&#x27;selector&#x27;,\n",
       "                                                         TextSelector(key=&#x27;processed&#x27;)),\n",
       "                                                        (&#x27;tfidf&#x27;,\n",
       "                                                         TfidfVectorizer(stop_words=&#x27;english&#x27;))])),\n",
       "                                       (&#x27;lda&#x27;,\n",
       "                                        LatentDirichletAllocation(learning_method=&#x27;online&#x27;,\n",
       "                                                                  n_components=8,\n",
       "                                                                  n_jobs=-1,\n",
       "                                                                  random_state=0)),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             param_grid={&#x27;classifier__min_samples_leaf&#x27;: [1, 2],\n",
       "                         &#x27;lda__n_components&#x27;: [5],\n",
       "                         &#x27;text__tfidf__max_df&#x27;: [0.9, 0.95],\n",
       "                         &#x27;text__tfidf__ngram_range&#x27;: [(1, 1), (1, 2)]},\n",
       "             scoring=make_scorer(my_scorer))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;text&#x27;,\n",
       "                                        Pipeline(steps=[(&#x27;selector&#x27;,\n",
       "                                                         TextSelector(key=&#x27;processed&#x27;)),\n",
       "                                                        (&#x27;tfidf&#x27;,\n",
       "                                                         TfidfVectorizer(stop_words=&#x27;english&#x27;))])),\n",
       "                                       (&#x27;lda&#x27;,\n",
       "                                        LatentDirichletAllocation(learning_method=&#x27;online&#x27;,\n",
       "                                                                  n_components=8,\n",
       "                                                                  n_jobs=-1,\n",
       "                                                                  random_state=0)),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             param_grid={&#x27;classifier__min_samples_leaf&#x27;: [1, 2],\n",
       "                         &#x27;lda__n_components&#x27;: [5],\n",
       "                         &#x27;text__tfidf__max_df&#x27;: [0.9, 0.95],\n",
       "                         &#x27;text__tfidf__ngram_range&#x27;: [(1, 1), (1, 2)]},\n",
       "             scoring=make_scorer(my_scorer))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;text&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;selector&#x27;, TextSelector(key=&#x27;processed&#x27;)),\n",
       "                                 (&#x27;tfidf&#x27;,\n",
       "                                  TfidfVectorizer(stop_words=&#x27;english&#x27;))])),\n",
       "                (&#x27;lda&#x27;,\n",
       "                 LatentDirichletAllocation(learning_method=&#x27;online&#x27;,\n",
       "                                           n_components=8, n_jobs=-1,\n",
       "                                           random_state=0)),\n",
       "                (&#x27;classifier&#x27;, RandomForestClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">text: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;selector&#x27;, TextSelector(key=&#x27;processed&#x27;)),\n",
       "                (&#x27;tfidf&#x27;, TfidfVectorizer(stop_words=&#x27;english&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TextSelector</label><div class=\"sk-toggleable__content\"><pre>TextSelector(key=&#x27;processed&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(learning_method=&#x27;online&#x27;, n_components=8, n_jobs=-1,\n",
       "                          random_state=0)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('text',\n",
       "                                        Pipeline(steps=[('selector',\n",
       "                                                         TextSelector(key='processed')),\n",
       "                                                        ('tfidf',\n",
       "                                                         TfidfVectorizer(stop_words='english'))])),\n",
       "                                       ('lda',\n",
       "                                        LatentDirichletAllocation(learning_method='online',\n",
       "                                                                  n_components=8,\n",
       "                                                                  n_jobs=-1,\n",
       "                                                                  random_state=0)),\n",
       "                                       ('classifier',\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             param_grid={'classifier__min_samples_leaf': [1, 2],\n",
       "                         'lda__n_components': [5],\n",
       "                         'text__tfidf__max_df': [0.9, 0.95],\n",
       "                         'text__tfidf__ngram_range': [(1, 1), (1, 2)]},\n",
       "             scoring=make_scorer(my_scorer))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def my_scorer(y_true, y_predicted):\n",
    "    # https://stackoverflow.com/questions/46208221/scikit-learn-gridsearch-custom-scoring-function\n",
    "    error = np.mean(y_true == y_predicted)\n",
    "    return error\n",
    "\n",
    "scoring_func = make_scorer(my_scorer, greater_is_better=True)\n",
    "\n",
    "\n",
    "hyperparameters = { 'text__tfidf__max_df': [0.9, 0.95],\n",
    "                    'text__tfidf__ngram_range': [(1,1), (1,2)],\n",
    "                   'lda__n_components': [5],\n",
    "                    'classifier__min_samples_leaf': [1,2]\n",
    "                  }\n",
    "#                    'classifier__max_depth': [50, 70],\n",
    "start_time = time.time()\n",
    "clf = GridSearchCV(pipeline, hyperparameters, cv=5, scoring=scoring_func)\n",
    "# Fit and tune model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f429fac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 1934.9938127994537\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Time:\", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e7c97f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__min_samples_leaf': 2,\n",
       " 'lda__n_components': 5,\n",
       " 'text__tfidf__max_df': 0.9,\n",
       " 'text__tfidf__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31dcec0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4025069637883008"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#refitting on entire training data using best settings\n",
    "clf.refit\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "probs = clf.predict_proba(X_test)\n",
    "\n",
    "np.mean(preds == y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
